{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b84e119-c489-4d0f-aef7-d6474e2032e5",
   "metadata": {},
   "source": [
    "Python scripts are required for large scale projects as they improve reproduceability.\n",
    "\n",
    "Normally, write a `notebook` for experimentation and visualisation, if its working, turn the most useful pieceds of code to python `scripts`.\n",
    "\n",
    "In this notebook, I am going to reproduce `04_custom_datasets.ipynb` but in `script mode`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7464a66f-c175-481b-bd8d-031d032591d5",
   "metadata": {},
   "source": [
    "#### 1. Get Data\n",
    "Since may vary every time, not required to make it into a script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2023eaf3-4808-4f39-b41c-541bd8378a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cd294b7-eb04-41bd-ae3a-b62a9f4d44a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder doesn't exist, creating one ...\n",
      "Downloading data ...\n",
      "Unzipping the file ...\n"
     ]
    }
   ],
   "source": [
    "# data path\n",
    "data_path = Path(\"../Dataset/\")\n",
    "\n",
    "# image path\n",
    "img_path = data_path / \"pizza_steak_sushi\"\n",
    "\n",
    "if img_path.is_dir():\n",
    "    print(\"Folder already exists, skipping download ...\")\n",
    "else:\n",
    "    print(\"Folder doesn't exist, creating one ...\")\n",
    "    \n",
    "    # create image folder\n",
    "    img_path.mkdir(parents=True)\n",
    "\n",
    "    # download the data\n",
    "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
    "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "        print(\"Downloading data ...\")\n",
    "\n",
    "        # write data\n",
    "        f.write(request.content)\n",
    "\n",
    "    # extract zip file\n",
    "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as f:\n",
    "        print(\"Unzipping the file ...\")\n",
    "\n",
    "        # extract file\n",
    "        f.extractall(img_path)\n",
    "\n",
    "    # delete zipfile\n",
    "    os.remove(data_path / \"pizza_steak_sushi.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdb3526c-36df-4b14-a8e6-1e19738e19ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path for saving scripts\n",
    "Path.mkdir(\"turning_modular\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa642cd-435b-49f8-b4dd-f21547351ee5",
   "metadata": {},
   "source": [
    "# 2 Data processing\n",
    "Note: we skip data exploration as we already have done it in `04` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83190db7-2fc1-4b41-a00e-42049144702b",
   "metadata": {},
   "source": [
    "### a. Create datasets (convert to tensors and manipulate if required)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2e7b8a-2abd-43df-b1b0-e6a39e5d2f35",
   "metadata": {},
   "source": [
    "### b. Creating datasets to dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36d05f41-fe65-4b68-b157-b44bbd901a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting turning_modular/data_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile turning_modular/data_setup.py\n",
    "'''\n",
    "Functionality for creating pyTorch datasets and dataloader for image classification'''\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# number of cores - useful for performing parallel jobs\n",
    "n_workers = os.cpu_count()\n",
    "\n",
    "def create_dataset_dataloader(train_dir : str, test_dir : str,\n",
    "                              transform : transforms.Compose,\n",
    "                              bach_size : int, n_workers : int = n_workers):\n",
    "    '''Creates training and testing dataloaders\n",
    "\n",
    "    Args:\n",
    "        train_dir : path of training data\n",
    "        test_dir  : path of testing data\n",
    "        transform : transformations to be performed\n",
    "        batch_size: mini-batch size\n",
    "        n_workers : number of cores per dataloader\n",
    "\n",
    "    Return:\n",
    "        A tuple of train_dataloader, test_dataloader, class_names\n",
    "        train_dataloader : dataloader of training data\n",
    "        test_dataloader  : dataloader of testing data\n",
    "        class_names      : list of label class names'''\n",
    "\n",
    "\n",
    "    # imageFolder to create datasets\n",
    "    # training dataset\n",
    "    train_data = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "\n",
    "    # testing dataset\n",
    "    test_data = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "    # class names\n",
    "    class_names = train_data.classes\n",
    "\n",
    "    # dataset to dataloader\n",
    "    # training dataloader\n",
    "    train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size,\n",
    "                                  shuffle=True, num_workers=n_workers, \n",
    "                                  pin_memory=True) # pin_memory - quicker transfer from cpu to gpu\n",
    "\n",
    "    # testing dataloader\n",
    "    test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size,\n",
    "                                  shuffle=False, num_workers=n_workers, \n",
    "                                  pin_memory=True) # no need to shuffle\n",
    "\n",
    "    return train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42d5bc0-ec4b-4cab-b3d5-36bd54d99f28",
   "metadata": {},
   "source": [
    "# 3. Build Model\n",
    "Make `TinyVGG()` model created in `03, 04 notebooks` into a script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe99afc4-8575-4253-a829-bb06ad9d18f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting turning_modular/model_builder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile turning_modular/model_builder.py\n",
    "'''\n",
    "Functionality to instantiate TinyVGG model'''\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class TinyVGG(nn.Module):\n",
    "    '''Creates TinyVGG Architecture by replicating https://poloclub.github.io/cnn-explainer/\n",
    "    Args:\n",
    "        in_channels : number of input channels (eg: 3 for RGB)\n",
    "        hid_units   : number of hidden channels or nodes for each layer\n",
    "        out_classes : number of classes for classification\n",
    "        image_shape : height or width of image\n",
    "\n",
    "    Creates:\n",
    "        model instance and can predictions'''\n",
    "\n",
    "    def __init__(self, in_channels: int, hid_units: int,\n",
    "                 out_classes: int, image_shape: int):\n",
    "        super().__init__()\n",
    "\n",
    "        PADDING, STRIDE, KERNEL, DILATION = 1, 2, 3, 1 # dilation: 1 is default\n",
    "\n",
    "        # 1st block\n",
    "        self.conv_block_1 = nn.Sequential(nn.Conv2d(in_channels=inp_features,\n",
    "                                                    out_channels=hidden_units,\n",
    "                                                   kernel_size=KERNEL, stride=1,\n",
    "                                                   padding=PADDING),\n",
    "                                          nn.ReLU(),\n",
    "                                          nn.Conv2d(in_channels=hidden_units,\n",
    "                                                    out_channels=hidden_units,\n",
    "                                                    kernel_size=KERNEL, stride=STRIDE,\n",
    "                                                    padding=PADDING),\n",
    "                                          nn.ReLU())\n",
    "        \n",
    "        \n",
    "        # required to compute input shape of classifier layer\n",
    "        H_out, W_out = H_W_out(image_shape, PADDING, KERNEL, STRIDE, DILATION)\n",
    "\n",
    "        # 2nd block\n",
    "        self.conv_block_2 = nn.Sequential(nn.Conv2d(in_channels=hidden_units,\n",
    "                                                    out_channels=hidden_units,\n",
    "                                                    kernel_size=KERNEL, stride=1,\n",
    "                                                    padding=PADDING),\n",
    "                                          nn.ReLU(),\n",
    "                                          nn.Conv2d(in_channels=hidden_units,\n",
    "                                                    out_channels=hidden_units,\n",
    "                                                    kernel_size=KERNEL, stride=STRIDE,\n",
    "                                                    padding=PADDING),\n",
    "                                          nn.ReLU())\n",
    "        \n",
    "        H_out, W_out = H_W_out(H_out, PADDING, KERNEL, STRIDE, DILATION)\n",
    "        \n",
    "        # output classifier layer\n",
    "        self.classifier = nn.Sequential(nn.Flatten(), \n",
    "                                        nn.Linear(in_features=hidden_units*H_out*W_out,\n",
    "                                                  out_features=out_shape))\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "\n",
    "        # operating w/o storing is faster - operation fusion\n",
    "        return self.classifier(self.conv_block_2(self.conv_block_1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df2e56a-d585-4d62-884f-ddf2b6b9bcd7",
   "metadata": {},
   "source": [
    "# 4. Training\n",
    "\n",
    "Build functions created in `04`,\n",
    "1. **train_step**\n",
    "2. **test_step**\n",
    "\n",
    "Finally combine both to,\n",
    "1. **train** - perform training for certain number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54b4065a-ad68-4b44-bb11-b346cbfc7110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing turning_modular/engine.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile turning_modular/engine.py\n",
    "'''functionality for training the model and evaluating it'''\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# training step\n",
    "def train_step(model: torch.nn.Module, data_loader: torch.utils.data.DataLoader,\n",
    "             loss_fn : torch.nn.Module, optimizer : torch.optim.Optimizer,\n",
    "             accuracy_fn, device : torch.device = device):\n",
    "    '''Trains a model for one epoch by preparing model for training and train the model \n",
    "    by calcuating the loss and computing the gradients of loss function\n",
    "\n",
    "    Args:\n",
    "        model      : model to be trained\n",
    "        data_loader: dataloader instance of data\n",
    "        loss_fn    : lost function to be minimised\n",
    "        optimizer  : optmizer to minimize the loss function\n",
    "        device     : cpu (or) cuda\n",
    "    \n",
    "    returns:\n",
    "        Tuple of loss and accuracy\n",
    "        train_loss    : Average training loss\n",
    "        train_accuracy: Average training accuracy'''\n",
    "\n",
    "    # training and test loss initialise\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    # model into training mode\n",
    "    model.train()\n",
    "\n",
    "    for X, y in data_loader:\n",
    "\n",
    "        # data on target device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # 1. forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. calculate loss and accuracy per batch\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        \n",
    "        train_acc += accuracy_fn(y_true=y,\n",
    "                                 y_pred=y_pred.argmax(dim=1)) # Go from logits -> pred labels\n",
    "\n",
    "        # 3.optimiser zero grad\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # 4.loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. step\n",
    "        optim.step()\n",
    "\n",
    "    # average training loss\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test_step(model : torch.nn.Module,\n",
    "              data_loader : torch.utils.data.DataLoader,\n",
    "              loss_fn : torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device : torch.device = device):\n",
    "\n",
    "    '''Tests model performance for single epoch\n",
    "\n",
    "    Args:\n",
    "        model      : model to be trained\n",
    "        data_loader: dataloader instance of data\n",
    "        loss_fn    : lost function to be minimised\n",
    "        device     : cpu (or) cuda\n",
    "    \n",
    "    returns:\n",
    "        Tuple of loss and accuracy\n",
    "        train_loss    : Average training loss\n",
    "        train_accuracy: Accuracy of training'''\n",
    "\n",
    "    # training and test loss initialise\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    # model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "\n",
    "            # data on target device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # 1. forward pass\n",
    "            test_pred = model(X)\n",
    "\n",
    "            # calculate loss\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "\n",
    "            test_acc += accuracy(y_true=y, y_pred=test_pred.argmax(dim=1)) # to get the labels and get the accuracy\n",
    "    \n",
    "        # avg test loss\n",
    "        test_loss /= len(data_loader)\n",
    "    \n",
    "        # average accuracy\n",
    "        test_acc /= len(data_loader)\n",
    "\n",
    "    return test_loss, test_acc\n",
    "\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          epochs:int, device:torch.device):\n",
    "    '''Trains and tests model for given number of epochs\n",
    "    \n",
    "    Args:\n",
    "        model: pytorch model to be trained and tested\n",
    "        train_data_loader: training dataloader instance of data\n",
    "        test_data_loader: testing dataloader instance of data\n",
    "        loss_fn    : lost function to be minimised\n",
    "        optimizer  : optmizer to minimize the loss function\n",
    "        epochs     : number of times a data is to be used for training\n",
    "        device     : cpu (or) cuda\n",
    "\n",
    "    returns:\n",
    "        dictionary of training and testing loss and accuracy'''\n",
    "\n",
    "    \n",
    "    results = {\"train_loss\": [], \"train_acc\": [],\n",
    "               \"test_loss\": [], \"test_acc\": []}\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model, dataloader=train_dataloader,\n",
    "                                         loss_fn=loss_fn, optimizer=optimizer,\n",
    "                                         device=device)\n",
    "        test_loss, test_acc = test_step(model=model, dataloader=test_dataloader,\n",
    "                                      loss_fn=loss_fn, device=device)\n",
    "        \n",
    "        print(f\"Model: {model.__class__.__name__} | train loss: {train_loss:.4f} | Train acc: {train_acc:.4f}%\")\n",
    "\n",
    "        print(f\"Model: {model.__class__.__name__} | Test loss: {test_loss:.4f}, test accuracy: {test_acc}% \\n\")\n",
    "\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128be460-5255-42cc-a499-c31f2f8b8849",
   "metadata": {},
   "source": [
    "# 5. Saving the model\n",
    "\n",
    "Its common practise to store helper functions in `utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5903d7cc-bbec-42f2-8ad7-dfeb83a84265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing turning_modular/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile turning_modular/utils.py\n",
    "'''\n",
    "Contains various utility function for model training and saving'''\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "def save_model(model: torch.nn.Module, target_dir: str,\n",
    "               model_name: str):\n",
    "    '''Saves a PyTorch model to a target directory.\n",
    "    Args:\n",
    "        model: model to save.\n",
    "        target_dir: directory for saving the model.\n",
    "        model_name: filename to be given to the model with extension.'''\n",
    "\n",
    "    # Create target directory\n",
    "    target_dir_path = Path(target_dir)\n",
    "    target_dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if not model_name.endswith(\".pth\"):\n",
    "        return \"Not .pth extension. change extension\"\n",
    "    else:\n",
    "        model_save_path = target_dir_path / model_name\n",
    "\n",
    "        print(\"Saving model ...\")\n",
    "        torch.save(obj=model.state_dict(), f= model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf99ede-5055-4aed-bf46-bcffe5d50d6d",
   "metadata": {},
   "source": [
    "# 6. Perform training at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b18074ca-edab-4d16-bcdf-ef6f0d7054ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting turning_modular/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile turning_modular/train.py\n",
    "\"\"\"\n",
    "Trains a PyTorch image classification model using device-agnostic code.\n",
    "\"\"\"\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import data_setup, engine, model_builder, utils\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Image Classification Data Loader')\n",
    "\n",
    "# Add arguments\n",
    "parser.add_argument('--train_dir', type=str, required=True,\n",
    "                    help='Path to the training data directory')\n",
    "parser.add_argument('--test_dir', type=str, required=True,\n",
    "                    help='Path to the testing data directory')\n",
    "parser.add_argument('--batch_size', type=int, default=32,\n",
    "                    help='Mini-batch size (default: 32)')\n",
    "parser.add_argument('--num_workers', type=int, default=os.cpu_count(),\n",
    "                    help='Number of worker threads for data loading (default: number of CPU cores)')\n",
    "parser.add_argument('--n_epochs', type=int, default=5,\n",
    "                    help='Number of epochs (default: 5)')\n",
    "parser.add_argument('--h_units', type=int, default=16,\n",
    "                    help='Number of hidden units in hidden layer (default: 16)')\n",
    "parser.add_argument('--lr', type=float, default=0.1,\n",
    "                    help='learning rate (default: 0.1)')\n",
    "parser.add_argument('--model_name', type=str, help='Model name', required=True)\n",
    "\n",
    "# Parse the arguments\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Setup hyperparameters\n",
    "n_epochs = 5\n",
    "batch_size = 16\n",
    "h_units = 10\n",
    "lr = 0.01\n",
    "\n",
    "# Setup directories\n",
    "train_dir = train_dir\n",
    "test_dir = test_dir\n",
    "\n",
    "# Setup target device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Create transforms\n",
    "data_transform = transforms.Compose([\n",
    "  transforms.Resize((64, 64)),\n",
    "  transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create DataLoaders with help from data_setup.py\n",
    "train_dataloader, test_dataloader, \\\n",
    "class_names = data_setup.create_dataset_dataloader(train_dir=train_dir,\n",
    "                                            test_dir=test_dir,\n",
    "                                            transform=data_transform,\n",
    "                                            batch_size=batch_size, n_workers=n_workers)\n",
    "\n",
    "# Create model with help from model_builder.py\n",
    "model = model_builder.TinyVGG(in_channels=3, hid_units=hid_units,\n",
    "                              out_classes=len(class_names), image_shape=64).to(device)\n",
    "\n",
    "# Set loss and optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=lr)\n",
    "\n",
    "# training and testing with help from engine.py\n",
    "engine.train(model=model,\n",
    "             train_dataloader=train_dataloader,\n",
    "             test_dataloader=test_dataloader,\n",
    "             loss_fn=loss_fn,\n",
    "             optimizer=optimizer,\n",
    "             epochs=n_epochs,\n",
    "             device=device)\n",
    "\n",
    "# Save the model with help from utils.py\n",
    "utils.save_model(model=model,\n",
    "                 target_dir=\"models\",\n",
    "                 model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cf3b8a1-5a4a-4398-b63f-0f52e1af33df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run as shell script\n",
    "!python ./turning_modular/train.py --model \"TinyVGG_script.pth\" --batch_size 32 --lr 0.01 --n_epochs 3 --model_name \"TinyVGG_script.pth\" --train_dir \"../Dataset/pizza_steak_sushi/train\" --test_dir \"../Dataset/pizza_steak_sushi/test\" --num_workers 2 --h_units 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_torch",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
